{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "from shutil import copyfile\n",
    "import fingerprint_enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "for file in os.listdir('./LipPrintDatabase/'):\n",
    "    img = cv2.imread('./LipPrintDatabase/' + str(file))\n",
    "    x = max(x, img.shape[0])\n",
    "    y = max(y, img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1444"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inp_shape, output_dim):\n",
    "    inputs = Input(inp_shape)\n",
    "    x = Conv2D(32, (9, 9), padding = 'same', activation = 'relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(64, (7, 7), padding = 'same', activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    pooledoutput = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(output_dim)(pooledoutput)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model1 = create_model((128, 128, 3), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      7808      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        100416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 114,724\n",
      "Trainable params: 114,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(vector):\n",
    "    (featsA, featsB) = vector\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape = (128, 128, 3))\n",
    "imgB = Input(shape = (128, 128, 3))\n",
    "featsA = model1(imgA)\n",
    "featsB = model1(imgB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidian_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          114724      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           model[0][0]                      \n",
      "                                                                 model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 114,726\n",
      "Trainable params: 114,726\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "labels = []\n",
    "x=738\n",
    "y=1444\n",
    "i=1\n",
    "for file in os.listdir('./LipPrintDatabase'):\n",
    "    img = cv2.imread('./LipPrintDatabase/' + str(file))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = (255-img)\n",
    "    enh = fingerprint_enhancer.enhance_Fingerprint(img)\n",
    "    print(i)\n",
    "    i+=1\n",
    "    padded_img = np.pad(enh, [((x-enh.shape[0])//2, ), ((y-enh.shape[1])//2, )], mode='constant')\n",
    "    cv2.imwrite('./ff/' + str(file), padded_img)\n",
    "    img_list.append(padded_img)\n",
    "    t = int(file[1:4])\n",
    "    labels.append(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img_pair.npy', img_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('label_pair.npy', label_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('img_pair.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)],\n",
       "        [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]],\n",
       "\n",
       "       [[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)],\n",
       "        [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]],\n",
       "\n",
       "       [[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)],\n",
       "        [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)],\n",
       "        [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]],\n",
       "\n",
       "       [[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)],\n",
       "        [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]],\n",
       "\n",
       "       [[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)],\n",
       "        [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]]], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for file in os.listdir('./ff/'):\n",
    "    img = load_img('./ff/' + file, target_size = (128, 128))\n",
    "    img = img_to_array(img)\n",
    "    temp.append(img)\n",
    "temp = np.asarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 128, 128, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('temp.npy', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d0aea5a3c8>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(temp1[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('labels.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = np.load('temp.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 128, 128, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pair = []\n",
    "label_pair = []\n",
    "numClasses = len(np.unique(labels))\n",
    "idx = [np.where(labels == i)[0]  for i in range(0, numClasses)]\n",
    "for i in range(len(img_list)):\n",
    "    cur_img = img_list[i]\n",
    "    cur_label = labels[i]\n",
    "    j = np.random.choice(idx[cur_label])\n",
    "    s_img = img_list[j]\n",
    "    img_pair.append([cur_img, s_img])\n",
    "    label_pair.append([1])\n",
    "    negIdx = np.where(labels != cur_label)[0]\n",
    "    negImage = img_list[np.random.choice(negIdx)]\n",
    "    img_pair.append([cur_img, negImage])\n",
    "    label_pair.append([0])\n",
    "    \n",
    "np_img_pair = np.array(img_pair)\n",
    "np_label_pair = np.array(label_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 2, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_label_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('np_img_pair.npy', np_img_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('np_label_pair.npy', np_label_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img_pair = np.load('np_img_pair.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_label_pair = np.load('np_label_pair.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 13s 180ms/step - loss: 1.6414 - accuracy: 0.5156\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6594 - accuracy: 0.4950\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.6385 - accuracy: 0.5181\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.6378 - accuracy: 0.5079\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.6394 - accuracy: 0.5163\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.6178 - accuracy: 0.5288\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.6125 - accuracy: 0.5177\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6104 - accuracy: 0.5247\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5937 - accuracy: 0.5597\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.5891 - accuracy: 0.5692\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.5619 - accuracy: 0.6142\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.5635 - accuracy: 0.6389\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.5522 - accuracy: 0.6361\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5498 - accuracy: 0.6529\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5467 - accuracy: 0.6653\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.5328 - accuracy: 0.6599\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.5489 - accuracy: 0.6719\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.5276 - accuracy: 0.6936\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 3s 140ms/step - loss: 0.5240 - accuracy: 0.6962\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 3s 140ms/step - loss: 0.5121 - accuracy: 0.7138\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.5134 - accuracy: 0.7388\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 0.5030 - accuracy: 0.7289\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 3s 149ms/step - loss: 0.4995 - accuracy: 0.7362\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 0.5129 - accuracy: 0.7554\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.5145 - accuracy: 0.7498\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.4873 - accuracy: 0.7535\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.4825 - accuracy: 0.7757\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 4s 194ms/step - loss: 0.4781 - accuracy: 0.7816\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 4s 179ms/step - loss: 0.4914 - accuracy: 0.7750\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 4s 188ms/step - loss: 0.4709 - accuracy: 0.7978\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 4s 197ms/step - loss: 0.4821 - accuracy: 0.7775\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.4774 - accuracy: 0.7667\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.4664 - accuracy: 0.7933\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.4498 - accuracy: 0.8046\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.4431 - accuracy: 0.8207\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 5s 205ms/step - loss: 0.4458 - accuracy: 0.81783s -\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 5s 222ms/step - loss: 0.4420 - accuracy: 0.8374\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 5s 236ms/step - loss: 0.4436 - accuracy: 0.8108\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 5s 243ms/step - loss: 0.4368 - accuracy: 0.8247\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 5s 216ms/step - loss: 0.4334 - accuracy: 0.8469\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 0.4300 - accuracy: 0.8358\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 5s 216ms/step - loss: 0.4215 - accuracy: 0.8346\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 5s 235ms/step - loss: 0.4252 - accuracy: 0.8449\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 5s 238ms/step - loss: 0.4344 - accuracy: 0.8170\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 0.4273 - accuracy: 0.8465\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 0.4291 - accuracy: 0.8561\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 6s 263ms/step - loss: 0.4090 - accuracy: 0.8283\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 6s 277ms/step - loss: 0.3974 - accuracy: 0.8609\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 6s 287ms/step - loss: 0.4038 - accuracy: 0.8613\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 6s 294ms/step - loss: 0.4025 - accuracy: 0.8708\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([np_img_pair[:, 0], np_img_pair[:, 1]], np_label_pair[:], batch_size = 64, epochs = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_test = []\n",
    "i=0\n",
    "for files in os.listdir('./ff/'):\n",
    "    t = int(files[1:4])\n",
    "    t-=1\n",
    "    if t==i:\n",
    "        img = load_img('./ff/' + files, target_size = (128, 128))\n",
    "        img = img_to_array(img)\n",
    "        img_list_test.append(img)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_test = np.array(img_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "img = load_img('U004L04.png', target_size = (128, 128))\n",
    "img = img_to_array(img)\n",
    "for i in img_list_test:\n",
    "    img = img.reshape((1, 128, 128, 3))\n",
    "    acc.append(model.predict([img, i.reshape((1, 128, 128, 3))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67235154]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.index(max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save/lip_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./save/lip_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
